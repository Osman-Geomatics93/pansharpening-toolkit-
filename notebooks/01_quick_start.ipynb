{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Pansharpening Toolkit - Quick Start Guide\n\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Osman-Geomatics93/pansharpening-toolkit-/blob/main/notebooks/01_quick_start.ipynb)\n\nThis notebook demonstrates the basic usage of the pansharpening toolkit.\n\n## Contents\n1. Setup & Installation (for Colab)\n2. Loading Images\n3. Classic Pansharpening Methods\n4. Deep Learning Models\n5. Quality Metrics"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 1. Setup & Installation\n\nRun this cell to install the toolkit (required for Google Colab)."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Install from GitHub (for Google Colab)\nimport subprocess\nimport sys\n\n# Check if running in Colab\ntry:\n    import google.colab\n    IN_COLAB = True\nexcept ImportError:\n    IN_COLAB = False\n\nif IN_COLAB:\n    print(\"Running in Google Colab - Installing pansharpening toolkit...\")\n    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \n                          \"git+https://github.com/Osman-Geomatics93/pansharpening-toolkit-.git\"])\nelse:\n    # Local installation\n    sys.path.insert(0, '..')\n\n# Import libraries\nimport torch\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom models import create_model, create_loss, AVAILABLE_MODELS\nfrom utils import compute_all_metrics\n\nprint(f\"PyTorch version: {torch.__version__}\")\nprint(f\"CUDA available: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\nprint(f\"\\nAvailable models: {AVAILABLE_MODELS}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Sample Data\n",
    "\n",
    "For demonstration, we'll create synthetic satellite imagery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create synthetic data\n",
    "def create_synthetic_data(height=256, width=256, ms_bands=4):\n",
    "    \"\"\"Create synthetic PAN and MS images for testing.\"\"\"\n",
    "    # Create a base pattern\n",
    "    x = np.linspace(0, 4*np.pi, width)\n",
    "    y = np.linspace(0, 4*np.pi, height)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    \n",
    "    # PAN: High resolution with fine details\n",
    "    pan = 0.5 + 0.3 * np.sin(X) * np.cos(Y) + 0.2 * np.sin(3*X) * np.sin(3*Y)\n",
    "    pan = np.clip(pan, 0, 1)\n",
    "    \n",
    "    # MS: Lower resolution, multiple bands\n",
    "    ms = np.zeros((ms_bands, height//4, width//4))\n",
    "    for i in range(ms_bands):\n",
    "        phase = i * np.pi / ms_bands\n",
    "        x_lr = np.linspace(0, 4*np.pi, width//4)\n",
    "        y_lr = np.linspace(0, 4*np.pi, height//4)\n",
    "        X_lr, Y_lr = np.meshgrid(x_lr, y_lr)\n",
    "        ms[i] = 0.5 + 0.3 * np.sin(X_lr + phase) * np.cos(Y_lr)\n",
    "    ms = np.clip(ms, 0, 1)\n",
    "    \n",
    "    return pan[np.newaxis], ms\n",
    "\n",
    "pan, ms = create_synthetic_data()\n",
    "print(f\"PAN shape: {pan.shape}\")\n",
    "print(f\"MS shape: {ms.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the data\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "axes[0].imshow(pan[0], cmap='gray')\n",
    "axes[0].set_title('PAN (High Resolution)')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(ms[:3].transpose(1, 2, 0))  # RGB\n",
    "axes[1].set_title('MS - RGB (Low Resolution)')\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(ms[3], cmap='Reds')\n",
    "axes[2].set_title('MS - NIR Band')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Inference\n",
    "\n",
    "Let's test different models on our synthetic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import zoom\n",
    "\n",
    "# Upsample MS to PAN resolution\n",
    "scale = pan.shape[1] // ms.shape[1]\n",
    "ms_up = np.array([zoom(band, scale, order=3) for band in ms])\n",
    "print(f\"Upsampled MS shape: {ms_up.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test a model\n",
    "model_name = 'pannet_cbam'\n",
    "model = create_model(model_name, ms_bands=4)\n",
    "model.eval()\n",
    "\n",
    "# Convert to tensors\n",
    "ms_tensor = torch.from_numpy(ms_up).unsqueeze(0).float()\n",
    "pan_tensor = torch.from_numpy(pan).unsqueeze(0).float()\n",
    "\n",
    "print(f\"Model: {model_name}\")\n",
    "print(f\"Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# Run inference\n",
    "with torch.no_grad():\n",
    "    fused = model(ms_tensor, pan_tensor)\n",
    "    fused = fused.squeeze(0).numpy()\n",
    "\n",
    "print(f\"Output shape: {fused.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "axes[0].imshow(ms_up[:3].transpose(1, 2, 0))\n",
    "axes[0].set_title('MS Upsampled (Input)')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(pan[0], cmap='gray')\n",
    "axes[1].set_title('PAN (Input)')\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(np.clip(fused[:3].transpose(1, 2, 0), 0, 1))\n",
    "axes[2].set_title(f'{model_name.upper()} (Output)')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compare All Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different models\n",
    "results = {}\n",
    "\n",
    "for model_name in ['pnn', 'pannet', 'pannet_cbam', 'panformer_lite']:\n",
    "    model = create_model(model_name, ms_bands=4)\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        fused = model(ms_tensor, pan_tensor)\n",
    "        results[model_name] = fused.squeeze(0).numpy()\n",
    "    \n",
    "    n_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"{model_name:15s}: {n_params:>10,} parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize all results\n",
    "fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
    "\n",
    "axes[0, 0].imshow(ms_up[:3].transpose(1, 2, 0))\n",
    "axes[0, 0].set_title('MS Upsampled')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "axes[0, 1].imshow(pan[0], cmap='gray')\n",
    "axes[0, 1].set_title('PAN')\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "for idx, (name, result) in enumerate(results.items()):\n",
    "    row, col = (idx + 2) // 3, (idx + 2) % 3\n",
    "    axes[row, col].imshow(np.clip(result[:3].transpose(1, 2, 0), 0, 1))\n",
    "    axes[row, col].set_title(name.upper())\n",
    "    axes[row, col].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate loss functions\n",
    "from models import CombinedLoss, AdvancedCombinedLoss\n",
    "\n",
    "# Create sample tensors\n",
    "pred = torch.randn(1, 4, 64, 64)\n",
    "target = torch.randn(1, 4, 64, 64)\n",
    "\n",
    "# Basic combined loss\n",
    "loss_fn = CombinedLoss()\n",
    "loss, loss_dict = loss_fn(pred, target)\n",
    "print(\"CombinedLoss:\")\n",
    "print(f\"  Total: {loss.item():.4f}\")\n",
    "for k, v in loss_dict.items():\n",
    "    print(f\"  {k}: {v:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced loss with SSIM and SAM\n",
    "advanced_loss = AdvancedCombinedLoss(\n",
    "    l1_weight=1.0,\n",
    "    mse_weight=0.5,\n",
    "    gradient_weight=0.1,\n",
    "    ssim_weight=0.2,\n",
    "    sam_weight=0.1\n",
    ")\n",
    "\n",
    "loss, loss_dict = advanced_loss(pred, target)\n",
    "print(\"\\nAdvancedCombinedLoss:\")\n",
    "print(f\"  Total: {loss.item():.4f}\")\n",
    "for k, v in loss_dict.items():\n",
    "    print(f\"  {k}: {v:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "- Creating and using pansharpening models\n",
    "- Comparing different architectures\n",
    "- Using various loss functions\n",
    "\n",
    "For full training, see `run_deep_learning.py` or the training notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}