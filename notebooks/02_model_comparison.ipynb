{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Model Architecture Comparison\n\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Osman-Geomatics93/pansharpening-toolkit-/blob/main/notebooks/02_model_comparison.ipynb)\n\nThis notebook provides a detailed comparison of all available pansharpening models.\n\n## Models Covered\n1. **PNN** - Basic 3-layer CNN\n2. **PanNet** - ResNet-style with high-pass filtering\n3. **DRPNN** - Deep Residual PanNet\n4. **PanNetCBAM** - PanNet with CBAM attention\n5. **MultiScalePanNet** - Feature pyramid architecture\n6. **PanFormer** - Transformer-based\n7. **PanFormerLite** - Lightweight transformer"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Install from GitHub (for Google Colab)\nimport subprocess\nimport sys\n\n# Check if running in Colab\ntry:\n    import google.colab\n    IN_COLAB = True\nexcept ImportError:\n    IN_COLAB = False\n\nif IN_COLAB:\n    print(\"Running in Google Colab - Installing pansharpening toolkit...\")\n    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \n                          \"git+https://github.com/Osman-Geomatics93/pansharpening-toolkit-.git\"])\nelse:\n    sys.path.insert(0, '..')\n\nimport torch\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom time import time\n\nfrom models import (\n    PNN, PanNet, DRPNN, PanNetCBAM, \n    MultiScalePanNet, PanFormer, PanFormerLite,\n    create_model, AVAILABLE_MODELS\n)\n\nprint(f\"PyTorch: {torch.__version__}\")\nprint(f\"CUDA available: {torch.cuda.is_available()}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect model statistics\n",
    "stats = []\n",
    "\n",
    "for model_name in AVAILABLE_MODELS:\n",
    "    model = create_model(model_name, ms_bands=4)\n",
    "    n_params = sum(p.numel() for p in model.parameters())\n",
    "    n_trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    \n",
    "    # Memory estimate (rough)\n",
    "    memory_mb = n_params * 4 / (1024 * 1024)  # 4 bytes per float32\n",
    "    \n",
    "    stats.append({\n",
    "        'Model': model_name,\n",
    "        'Parameters': n_params,\n",
    "        'Trainable': n_trainable,\n",
    "        'Memory (MB)': memory_mb\n",
    "    })\n",
    "\n",
    "# Display as table\n",
    "print(f\"{'Model':<18} {'Parameters':>12} {'Memory (MB)':>12}\")\n",
    "print(\"-\" * 45)\n",
    "for s in stats:\n",
    "    print(f\"{s['Model']:<18} {s['Parameters']:>12,} {s['Memory (MB)']:>12.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize parameter counts\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "models = [s['Model'] for s in stats]\n",
    "params = [s['Parameters'] / 1000 for s in stats]  # in thousands\n",
    "\n",
    "bars = ax.bar(models, params, color='steelblue', edgecolor='navy')\n",
    "ax.set_ylabel('Parameters (K)')\n",
    "ax.set_title('Model Parameter Comparison')\n",
    "ax.set_xticklabels(models, rotation=45, ha='right')\n",
    "\n",
    "# Add value labels\n",
    "for bar, param in zip(bars, params):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 10,\n",
    "            f'{param:.0f}K', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Speed Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark inference speed\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# Create test input\n",
    "ms = torch.randn(1, 4, 256, 256).to(device)\n",
    "pan = torch.randn(1, 1, 256, 256).to(device)\n",
    "\n",
    "speed_stats = []\n",
    "n_runs = 10\n",
    "\n",
    "for model_name in AVAILABLE_MODELS:\n",
    "    model = create_model(model_name, ms_bands=4).to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # Warmup\n",
    "    with torch.no_grad():\n",
    "        for _ in range(3):\n",
    "            _ = model(ms, pan)\n",
    "    \n",
    "    # Benchmark\n",
    "    if device.type == 'cuda':\n",
    "        torch.cuda.synchronize()\n",
    "    \n",
    "    start = time()\n",
    "    with torch.no_grad():\n",
    "        for _ in range(n_runs):\n",
    "            _ = model(ms, pan)\n",
    "            if device.type == 'cuda':\n",
    "                torch.cuda.synchronize()\n",
    "    \n",
    "    elapsed = (time() - start) / n_runs * 1000  # ms\n",
    "    speed_stats.append({'Model': model_name, 'Time (ms)': elapsed})\n",
    "    print(f\"{model_name:<18}: {elapsed:>8.2f} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize speed\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "models = [s['Model'] for s in speed_stats]\n",
    "times = [s['Time (ms)'] for s in speed_stats]\n",
    "\n",
    "bars = ax.barh(models, times, color='coral', edgecolor='darkred')\n",
    "ax.set_xlabel('Inference Time (ms)')\n",
    "ax.set_title(f'Inference Speed Comparison (256x256, {device})')\n",
    "\n",
    "# Add value labels\n",
    "for bar, t in zip(bars, times):\n",
    "    ax.text(bar.get_width() + 0.5, bar.get_y() + bar.get_height()/2,\n",
    "            f'{t:.1f}ms', va='center', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show model architecture\n",
    "model_name = 'pannet_cbam'\n",
    "model = create_model(model_name, ms_bands=4)\n",
    "print(f\"=== {model_name.upper()} ===\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show PanFormerLite architecture\n",
    "model = create_model('panformer_lite', ms_bands=4)\n",
    "print(\"=== PANFORMER_LITE ===\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary\n",
    "summary = {\n",
    "    'pnn': {'Type': 'CNN', 'Attention': 'No', 'Multi-scale': 'No', 'Best For': 'Baseline'},\n",
    "    'pannet': {'Type': 'ResNet', 'Attention': 'No', 'Multi-scale': 'No', 'Best For': 'General use'},\n",
    "    'drpnn': {'Type': 'Deep ResNet', 'Attention': 'No', 'Multi-scale': 'No', 'Best For': 'Complex scenes'},\n",
    "    'pannet_cbam': {'Type': 'ResNet+Attn', 'Attention': 'CBAM', 'Multi-scale': 'No', 'Best For': 'Balanced'},\n",
    "    'mspannet': {'Type': 'FPN', 'Attention': 'CBAM', 'Multi-scale': 'Yes', 'Best For': 'Multi-scale features'},\n",
    "    'panformer': {'Type': 'Transformer', 'Attention': 'Self+Cross', 'Multi-scale': 'No', 'Best For': 'Best quality'},\n",
    "    'panformer_lite': {'Type': 'Window Trans.', 'Attention': 'Window', 'Multi-scale': 'No', 'Best For': 'Efficient transformer'}\n",
    "}\n",
    "\n",
    "print(f\"{'Model':<16} {'Type':<14} {'Attention':<12} {'Multi-scale':<12} {'Best For':<20}\")\n",
    "print(\"-\" * 75)\n",
    "for model, info in summary.items():\n",
    "    print(f\"{model:<16} {info['Type']:<14} {info['Attention']:<12} {info['Multi-scale']:<12} {info['Best For']:<20}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendations\n",
    "\n",
    "| Use Case | Recommended Model |\n",
    "|----------|------------------|\n",
    "| Quick prototyping | `pnn` |\n",
    "| General purpose | `pannet` |\n",
    "| Best quality | `panformer_lite` (with 100+ epochs) |\n",
    "| Limited compute | `pannet_cbam` |\n",
    "| Research/SOTA | `panformer` |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}